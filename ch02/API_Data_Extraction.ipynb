{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/c-w-m/btap/blob/master/ch02/API_Data_Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3CQ7o89w4h83"
   },
   "source": [
    "Original source: [**Blueprints for Text Analysis Using Python**](https://github.com/blueprints-for-text-analytics-python/blueprints-text)<br>\n",
    "Jens Albrecht, Sidharth Ramachandran, Christian Winkler\n",
    "\n",
    "# Chapter 2: API Data Extraction<div class='tocSkip'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqAdiKWo4h88"
   },
   "source": [
    "## Remark<div class='tocSkip'/>\n",
    "\n",
    "The code in this notebook differs slightly from the printed book. For example we frequently use pretty print (`pp.pprint`) instead of `print` and `tqdm`'s `progress_apply` instead of Pandas' `apply`. \n",
    "\n",
    "Moreover, several layout and formatting commands, like `figsize` to control figure size or subplot commands are removed in the book.\n",
    "\n",
    "You may also find some lines marked with three hashes ###. Those are not in the book as well as they don't contribute to the concept.\n",
    "\n",
    "All of this is done to simplify the code in the book and put the focus on the important parts instead of formatting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GtHO_6sI4h89"
   },
   "source": [
    "## Setup<div class='tocSkip'/>\n",
    "\n",
    "Set directory locations. If working on Google Colab: copy files and install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XHSKuk794h8-",
    "outputId": "93263f74-e3bb-4f8b-adbd-9baa9972ef8a"
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/c-w-m/btap/raw/master'\n",
    "    os.system(f'wget {GIT_ROOT}/ch02/setup.py')\n",
    "\n",
    "%run -i setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "soFHeYc34h8_"
   },
   "source": [
    "## Load Python Settings<div class=\"tocSkip\"/>\n",
    "\n",
    "Common imports, defaults for formatting in Matplotlib, Pandas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqbpfFGD4h8_"
   },
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/settings.py\"\n",
    "\n",
    "if ON_COLAB:\n",
    "    %reload_ext autoreload\n",
    "    %autoreload 2\n",
    "\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append(BASE_DIR + '/packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mvw4DlyJ4h8_"
   },
   "outputs": [],
   "source": [
    "# adjust matplotlib resolution for book version\n",
    "matplotlib.rcParams.update({'figure.dpi': 200 })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xKleAIgZ4h9A"
   },
   "source": [
    "# How to use APIs to extract and derive insights from text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAnbyI9L4h9A"
   },
   "source": [
    "# Application Programming Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0zR9KYO94h9A"
   },
   "source": [
    "# Blueprint - Extracting data from an API using the requests module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ANXnE6sa4h9A",
    "outputId": "84332de7-06cd-44ed-abb4-dafee777a115"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get('https://api.github.com/repositories',\n",
    "                        headers={'Accept': 'application/vnd.github.v3+json'})\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BciM9BV4h9B",
    "outputId": "51f4b4fa-fa46-4d69-abd2-46e12c4693c5"
   },
   "outputs": [],
   "source": [
    "print('encoding: {}'.format(response.encoding))\n",
    "print('Content-Type: {}'.format(response.headers['Content-Type']))\n",
    "print('server: {}'.format(response.headers['server']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2lbsnQ3e4h9B",
    "outputId": "54812e87-77fc-4aa7-bcab-f6c7b7f310c7"
   },
   "outputs": [],
   "source": [
    "response.headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eL6vGlw54h9C",
    "outputId": "a1660e84-eb25-4f40-e93b-a3832a2a9834"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "print(json.dumps(response.json()[0], indent=2)[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQagTL8C4h9C",
    "outputId": "6bc13e0a-c92d-49b0-97fe-048a4b32e31a"
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://api.github.com/search/repositories')\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KVZmWprb4h9C",
    "outputId": "c1083488-ef31-4432-c7c3-f5ddd7d3a94c"
   },
   "outputs": [],
   "source": [
    "response = requests.get('https://api.github.com/search/repositories',\n",
    "    params={'q': 'data_science+language:python'},\n",
    "    headers={'Accept': 'application/vnd.github.v3.text-match+json'})\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 155
    },
    "id": "9oFPy0_v4h9D",
    "outputId": "34b7a370-2553-4c6c-9d15-5e1a64074f54"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display  ###\n",
    "def printmd(string):  ###\n",
    "    display(Markdown(string))  ###\n",
    "\n",
    "for item in response.json()['items'][:5]:\n",
    "    printmd('**' + item['name'] + '**' + ': repository ' +\n",
    "            item['text_matches'][0]['property'] + ' - \\\"*' +\n",
    "            item['text_matches'][0]['fragment'] + '*\\\" matched with ' + '**' +\n",
    "            item['text_matches'][0]['matches'][0]['text'] + '**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LQDa4_CR4h9D",
    "outputId": "cf08f15d-728c-4fd7-c5ee-d81c35036244"
   },
   "outputs": [],
   "source": [
    "response = requests.get(\n",
    "    'https://api.github.com/repos/pytorch/pytorch/issues/comments')\n",
    "print('Response Code', response.status_code)\n",
    "print('Number of comments', len(response.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d45gF0RO4h9D",
    "outputId": "a92ef30d-e0e6-4718-baa2-1794e3755967"
   },
   "outputs": [],
   "source": [
    "response.links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GxEcy5Ij4h9E"
   },
   "outputs": [],
   "source": [
    "def get_all_pages(url, params=None, headers=None):\n",
    "    output_json = []\n",
    "    response = requests.get(url, params=params, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        output_json = response.json()\n",
    "        if 'next' in response.links:\n",
    "            next_url = response.links['next']['url']\n",
    "            if next_url is not None:\n",
    "                output_json += get_all_pages(next_url, params, headers)\n",
    "    return output_json\n",
    "\n",
    "\n",
    "out = get_all_pages(\n",
    "    \"https://api.github.com/repos/pytorch/pytorch/issues/comments\",\n",
    "    params={\n",
    "        'since': '2020-07-01T10:00:01Z',\n",
    "        'sorted': 'created',\n",
    "        'direction': 'desc'\n",
    "    },\n",
    "    headers={'Accept': 'application/vnd.github.v3+json'})\n",
    "df = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W1eRSNmJ4h9E"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "if ('body' in df.index):\n",
    "    print(df['body'].count())\n",
    "    print(df[['id','created_at','body']].sample(1, random_state=42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Scp67pud4h9E",
    "outputId": "7ac5f708-dd61-4dd7-f35d-6edbb2d95ce8"
   },
   "outputs": [],
   "source": [
    "response = requests.head(\n",
    "    'https://api.github.com/repos/pytorch/pytorch/issues/comments')\n",
    "print('X-Ratelimit-Limit', response.headers['X-Ratelimit-Limit'])\n",
    "print('X-Ratelimit-Remaining', response.headers['X-Ratelimit-Remaining'])\n",
    "\n",
    "# Converting UTC time to human-readable format\n",
    "import datetime\n",
    "print(\n",
    "    'Rate Limits reset at',\n",
    "    datetime.datetime.fromtimestamp(int(\n",
    "        response.headers['X-RateLimit-Reset'])).strftime('%c'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1MgKQF64h9F"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "def handle_rate_limits(response):\n",
    "    now = datetime.now()\n",
    "    reset_time = datetime.fromtimestamp(\n",
    "        int(response.headers['X-RateLimit-Reset']))\n",
    "    remaining_requests = response.headers['X-Ratelimit-Remaining']\n",
    "    remaining_time = (reset_time - now).total_seconds()\n",
    "    intervals = remaining_time / (1.0 + int(remaining_requests))\n",
    "    print('Sleeping for', intervals)\n",
    "    time.sleep(intervals)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wap8wz7Z4h9F",
    "outputId": "20b2eff2-480d-47c9-98b2-c2db18cebf16"
   },
   "outputs": [],
   "source": [
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    status_forcelist=[500, 503, 504],\n",
    "    backoff_factor=1\n",
    ")\n",
    "\n",
    "retry_adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", retry_adapter)\n",
    "http.mount(\"http://\", retry_adapter)\n",
    "\n",
    "response = http.get('https://api.github.com/search/repositories',\n",
    "                   params={'q': 'data_science+language:python'})\n",
    "\n",
    "for item in response.json()['items'][:5]:\n",
    "    print(item['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V8WiV4hg4h9G"
   },
   "outputs": [],
   "source": [
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry\n",
    "\n",
    "retry_strategy = Retry(\n",
    "    total=5,\n",
    "    status_forcelist=[500, 503, 504],\n",
    "    backoff_factor=1\n",
    ")\n",
    "\n",
    "retry_adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "\n",
    "http = requests.Session()\n",
    "http.mount(\"https://\", retry_adapter)\n",
    "http.mount(\"http://\", retry_adapter)\n",
    "\n",
    "def get_all_pages(url, param=None, header=None):\n",
    "    output_json = []\n",
    "    response = http.get(url, params=param, headers=header)\n",
    "    if response.status_code == 200:\n",
    "        output_json = response.json()\n",
    "        if 'next' in response.links:\n",
    "            next_url = response.links['next']['url']\n",
    "            if (next_url is not None) and (handle_rate_limits(response)): \n",
    "                output_json += get_all_pages(next_url, param, header)\n",
    "    return output_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-60nJVUQ4h9G"
   },
   "outputs": [],
   "source": [
    "out = get_all_pages(\"https://api.github.com/repos/pytorch/pytorch/issues/comments\", param={'since': '2020-04-01T00:00:01Z'})\n",
    "df = pd.DataFrame(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oidxJdOm4h9G"
   },
   "source": [
    "# Blueprint - Extracting Twitter data with Tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FaDCDM3x4h9G",
    "outputId": "8cdadfef-c7e0-4fe3-8acf-6145639b0948"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "\n",
    "app_api_key = 'YOUR_APP_KEY_HERE' \n",
    "app_api_secret_key = 'YOUR_APP_SECRET_HERE'\n",
    "\n",
    "app_api_key = 'CWIBFKPrcOU4GsdRr6J5fpaps'\n",
    "app_api_secret_key = 'SghP0LINUECDj0PzIi1vmDfRtNopqJNfb5xd3fH7XpO9ZaEtme'\n",
    "\n",
    "auth = tweepy.AppAuthHandler(app_api_key, app_api_secret_key)\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "print('API Host: {}'.format(api.host))\n",
    "print('API Version: {}'.format(api.api_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "_Sys0uG14h9H",
    "outputId": "fb0546b3-a9c8-49a0-cb73-7585596bc5aa"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "search_term = 'cryptocurrency'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "                       q=search_term,\n",
    "                       lang=\"en\").items(100)\n",
    "\n",
    "retrieved_tweets = [tweet._json for tweet in tweets]\n",
    "df = pd.json_normalize(retrieved_tweets)\n",
    "\n",
    "df[['text']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YDQNGHPx4h9H",
    "outputId": "00fabc2a-3bb0-46c5-e9b3-f1de649fe1f6"
   },
   "outputs": [],
   "source": [
    "# Note: the following code might return 'Rate limit reached. Sleeping for: 750\n",
    "api = tweepy.API(auth,\n",
    "                 wait_on_rate_limit=True,\n",
    "                 wait_on_rate_limit_notify=True,\n",
    "                 retry_count=5,\n",
    "                 retry_delay=10)\n",
    "\n",
    "search_term = 'cryptocurrency OR crypto -filter:retweets'\n",
    "\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "                       q=search_term,\n",
    "                       lang=\"en\",\n",
    "                       tweet_mode='extended',\n",
    "                       count=30).items(12000)\n",
    "\n",
    "retrieved_tweets = [tweet._json for tweet in tweets]\n",
    "\n",
    "df = pd.json_normalize(retrieved_tweets)\n",
    "print('Number of retrieved tweets {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "id": "2HRyhtJC4h9H",
    "outputId": "dfb2cab2-ec83-481a-f246-e66a86c7a290"
   },
   "outputs": [],
   "source": [
    "df[['created_at','full_text','entities.hashtags']].sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V2OaIcXO4h9I"
   },
   "outputs": [],
   "source": [
    "def extract_entities(entity_list):\n",
    "    entities = set()\n",
    "    if len(entity_list) != 0:\n",
    "        for item in entity_list:\n",
    "            for key,value in item.items():\n",
    "                if key == 'text':\n",
    "                    entities.add(value.lower())\n",
    "    return list(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 385
    },
    "id": "6EBa0C4a4h9I",
    "outputId": "044ecf02-d5e4-4872-dac5-2f1b39aad943"
   },
   "outputs": [],
   "source": [
    "df['Entities'] = df['entities.hashtags'].apply(extract_entities)\n",
    "pd.Series(np.concatenate(df['Entities'])).value_counts()[:25].plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-sN231ag4h9I",
    "outputId": "92c8fada-2d50-447e-8d59-aad88c65511a"
   },
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "tweets = tweepy.Cursor(api.user_timeline,\n",
    "                       screen_name='MercedesAMGF1',\n",
    "                       lang=\"en\",\n",
    "                       tweet_mode='extended',\n",
    "                       count=100).items(5000)\n",
    "\n",
    "retrieved_tweets = [tweet._json for tweet in tweets]\n",
    "df = pd.io.json.json_normalize(retrieved_tweets)\n",
    "print('Number of retrieved tweets {}'.format(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eArk--kh4h9I"
   },
   "outputs": [],
   "source": [
    "def get_user_timeline(screen_name):\n",
    "    api = tweepy.API(auth,\n",
    "                     wait_on_rate_limit=True,\n",
    "                     wait_on_rate_limit_notify=True)\n",
    "    tweets = tweepy.Cursor(api.user_timeline,\n",
    "                           screen_name=screen_name,\n",
    "                           lang=\"en\",\n",
    "                           tweet_mode='extended',\n",
    "                           count=200).items()\n",
    "    retrieved_tweets = [tweet._json for tweet in tweets]\n",
    "    df = pd.io.json.json_normalize(retrieved_tweets)\n",
    "    df = df[~df['retweeted_status.id'].isna()]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8-kKpgn4h9J",
    "outputId": "ecf5d9b7-a7cd-42f6-c9dd-7bdab9ec9e42"
   },
   "outputs": [],
   "source": [
    "df_mercedes = get_user_timeline('MercedesAMGF1')\n",
    "print('Number of Tweets from Mercedes {}'.format(len(df_mercedes)))\n",
    "df_ferrari = get_user_timeline('ScuderiaFerrari')\n",
    "print('Number of Tweets from Ferrari {}'.format(len(df_ferrari)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TYijcpt4h9J"
   },
   "outputs": [],
   "source": [
    "import regex as re\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "RE_LETTER = re.compile(r'\\b\\p{L}{2,}\\b')\n",
    "\n",
    "def tokenize(text):\n",
    "    return RE_LETTER.findall(text)\n",
    "\n",
    "def remove_stop(tokens):\n",
    "    return [t for t in tokens if t.lower() not in stopwords]\n",
    "\n",
    "pipeline = [str.lower, tokenize, remove_stop]\n",
    "\n",
    "def prepare(text):\n",
    "    tokens = text\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens\n",
    "\n",
    "def count_words(df, column='tokens', preprocess=None, min_freq=2):\n",
    "\n",
    "    # process tokens and update counter\n",
    "    def update(doc):\n",
    "        tokens = doc if preprocess is None else preprocess(doc)\n",
    "        counter.update(tokens)\n",
    "\n",
    "    # create counter and run through all data\n",
    "    counter = Counter()\n",
    "    df[column].map(update)\n",
    "\n",
    "    # transform counter into data frame\n",
    "    freq_df = pd.DataFrame.from_dict(counter, orient='index', columns=['freq'])\n",
    "    freq_df = freq_df.query('freq >= @min_freq')\n",
    "    freq_df.index.name = 'token'\n",
    "    \n",
    "    return freq_df.sort_values('freq', ascending=False)\n",
    "\n",
    "def wordcloud(word_freq, title=None, max_words=200, stopwords=None):\n",
    "\n",
    "    wc = WordCloud(width=800, height=400, \n",
    "                   background_color= \"black\", colormap=\"Paired\", \n",
    "                   max_font_size=150, max_words=max_words)\n",
    "    \n",
    "    # convert data frame into dict\n",
    "    if type(word_freq) == pd.Series:\n",
    "        counter = Counter(word_freq.fillna(0).to_dict())\n",
    "    else:\n",
    "        counter = word_freq\n",
    "\n",
    "    # filter stop words in frequency counter\n",
    "    if stopwords is not None:\n",
    "        counter = {token:freq for (token, freq) in counter.items() \n",
    "                              if token not in stopwords}\n",
    "    wc.generate_from_frequencies(counter)\n",
    " \n",
    "    plt.title(title) \n",
    "\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m7fq0tEX4h9J"
   },
   "outputs": [],
   "source": [
    "def wordcloud_blueprint(df, colName, max_words, num_stopwords):\n",
    "    # Step 1: Convert input text column into tokens\n",
    "    df['tokens'] = df[colName].map(prepare)\n",
    "    \n",
    "    # Step 2: Determine the frequency of each of the tokens\n",
    "    freq_df = count_words(df)\n",
    "    \n",
    "    # Step 3: Generate the wordcloud using the frequencies controlling for stopwords\n",
    "    wordcloud(freq_df['freq'], max_words, stopwords=freq_df.head(num_stopwords).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 342
    },
    "id": "QEQRbONJ4h9K",
    "outputId": "e87bce66-e0f4-44b0-ab97-9d09280d168b"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "wordcloud_blueprint(df_mercedes, 'full_text',\n",
    "                    max_words=100,\n",
    "                    num_stopwords=5)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "wordcloud_blueprint(df_ferrari, 'full_text',\n",
    "                    max_words=100,\n",
    "                    num_stopwords=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g0tdwVlv4h9K"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "class FileStreamListener(tweepy.StreamListener):\n",
    "    \n",
    "    def __init__(self, max_tweets=math.inf):\n",
    "        self.num_tweets = 0\n",
    "        self.TWEETS_FILE_SIZE = 10\n",
    "        self.num_files = 0\n",
    "        self.tweets = []\n",
    "        self.max_tweets = max_tweets      \n",
    "    \n",
    "    def on_data(self, data):\n",
    "        while (self.num_files * self.TWEETS_FILE_SIZE < self.max_tweets):\n",
    "            self.tweets.append(json.loads(data))\n",
    "            self.num_tweets += 1\n",
    "            if (self.num_tweets < self.TWEETS_FILE_SIZE):\n",
    "                return True\n",
    "            else:\n",
    "                filename = 'Tweets_' + str(datetime.now().time()) + '.txt'\n",
    "                print(self.TWEETS_FILE_SIZE, 'Tweets saved to', filename)\n",
    "                file = open(filename, \"w\")\n",
    "                json.dump(self.tweets, file)\n",
    "                file.close()\n",
    "                self.num_files += 1\n",
    "                self.tweets = []\n",
    "                self.num_tweets = 0\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def on_error(self, status_code):\n",
    "        if status_code == 420:\n",
    "            print('Too many requests were made, please stagger requests')\n",
    "            return False\n",
    "        else:\n",
    "            print('Error {}'.format(status_code))\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDYQJ4li4h9K"
   },
   "outputs": [],
   "source": [
    "user_access_token = 'YOUR_USER_ACCESS_TOKEN_HERE'\n",
    "user_access_secret = 'YOUR_USER_ACCESS_SECRET_HERE'\n",
    "\n",
    "app_api_key = 'CWIBFKPrcOU4GsdRr6J5fpaps'\n",
    "app_api_secret_key = 'SghP0LINUECDj0PzIi1vmDfRtNopqJNfb5xd3fH7XpO9ZaEtme'\n",
    "\n",
    "auth = tweepy.OAuthHandler(app_api_key, app_api_secret_key)\n",
    "auth.set_access_token(user_access_token, user_access_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RWZUgDt4h9L",
    "outputId": "937304ef-0fd8-431a-ba25-c03bd550459f"
   },
   "outputs": [],
   "source": [
    "fileStreamListener = FileStreamListener(20)\n",
    "fileStream = tweepy.Stream(auth=api.auth,\n",
    "                           listener=fileStreamListener,\n",
    "                           tweet_mode='extended')\n",
    "fileStream.filter(track=['cryptocurrency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 673
    },
    "id": "6CCv0RwO4h9L",
    "outputId": "57e471ea-eacd-469c-94a7-cccc839bc169"
   },
   "outputs": [],
   "source": [
    "df = pd.json_normalize(json.load(open('Tweets_01:01:36.656960.txt')))\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bA0X_ocj4h9L",
    "outputId": "ec8b65bf-45e7-4152-fd16-7b1af7f48481"
   },
   "outputs": [],
   "source": [
    "import wikipediaapi\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia(\n",
    "        language='en',\n",
    "        extract_format=wikipediaapi.ExtractFormat.WIKI\n",
    ")\n",
    "\n",
    "p_wiki = wiki_wiki.page('Cryptocurrency')\n",
    "print(p_wiki.text[:200], '....')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IF5jpIht4h9L"
   },
   "source": [
    "# Closing Remarks"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "API_Data_Extraction.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "btap38",
   "language": "python",
   "name": "btap38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
